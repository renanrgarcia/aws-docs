# ElastiCache Strategies

- Is data out of date?
  - Data could be out of date by a few seconds or minutes (eventual consistency)
- Is caching effective for that data?
  - Pattern: data changing slowly, few keys are frequently accessed
  - Antipattern: data changing rapidly, many keys are accessed infrequently
- Is data structured well for caching?
  - E.g.: key value caching, or caching of aggregation results
- Which caching design pattern is best?

## Lazy Loading/Cache-aside/Lazy Population

- Application checks cache first, if not found, retrieves from database and stores in cache.
  - Cache miss: get from database, put in cache
  - Cache hit: get from cache
- Use case: user profile, product catalog
- Pros:
  - Only frequently accessed data is cached (the cache is not filled with data that is never used)
  - Node failures are less impactful (just increased latency on cache miss)
- Cons:
  - Cache misses penalty that results in 3 round trips (application to cache, cache to database, database to application), noticeable latency spike (may be bad user experience)
  - Stale data: data can be updated in database but not in cache
- Example in C#:

```csharp
 // Example usage: Retrieve a user by ID, using cache-aside pattern
User user = GetUser(userId);

/// </summary>
/// <param name="userId">The unique identifier of the user.</param>
/// <returns>The User object corresponding to the given userId.</returns>
public User GetUser(string userId)
{
    User user = cache.Get(userId);

    // Cache miss
    if (user == null)
    {
        user = database.GetUser(userId);
        // Populate cache and set an expiration time
        cache.Set(userId, user, TimeSpan.FromMinutes(10));
    }

    return user;
}
```

## Write Through

- Add or update data in cache and database at the same time.
  - Cache hit: update cache and database
- Use case: social media feed, shopping cart
- Pros:
  - Data in cache is never stale, reads are quick
  - Write penalty instead of read penalty: only 2 round trips (write to cache, write to database)
- Cons:
  - Missing data until it is added/updated in the DB (cold cache). To mitigate, apply a lazy loading strategy on cache miss as well.
  - Cache churn: frequently updated data can lead to high cache turnover, reducing cache effectiveness.
- Example in C#:

```csharp
// Example usage: Update a user's profile, using write-through caching pattern
UserProfile profile = new UserProfile { Name = "Jane Doe", Age = 30 };
UpdateUserProfile(userId, profile);

public void UpdateUserProfile(string userId, UserProfile profile)
{
    // Update cache
    cache.Set(userId, profile);

    // Update database
    database.UpdateUserProfile(userId, profile);
}
```

## Cache Eviction/TTL(Time to Live)

- Cache eviction is the process of removing data from the cache to free up space or to ensure that stale data is not served.
- Three common cache eviction policies:
  - Explicit deletion: manually remove specific items from the cache when they are no longer needed or when they become stale.
  - Least Recently Used (LRU): removes the least recently accessed items first.
  - Time to Live (TTL): sets an expiration time for each cached item, after which the item is automatically removed from the cache.
- TTL is helpful for data that changes frequently or has a known lifespan. E.g., leaderboards, comment sections, activity streams.
- TTL can range from seconds to hours or days, depending on the use case.
- If too many evictions occur, it may indicate that the cache size is too small or that the eviction policy needs to be adjusted.

## Wisdom advices

- Lazy loading/cache-aside is easy to implement and works well for many use cases, especially when read-heavy workloads are involved.
- Write-through is usually combined with lazy loading as targeted for the queries or workloads that benefit from this optimization.
- Setting TTL is usually not a bad idea, except when you're using Write-Through. Set it to a sensible value based on how often the underlying data changes and how fresh you need the data to be.
- Only cache what you need (User profiles, product catalogs, blog posts). Avoid caching large datasets that are infrequently accessed.
- Quote: "There are only two hard things in Computer Science: cache invalidation and naming things." - Phil Karlton
